page: "CV - Sumit Kumar Rai"
name: "Sumit Kumar Rai"
location: "Kathmandu, Nepal"
linkedin:
  text: "linkedin.com/in/sumit-sampang-rai"
  url: "https://www.linkedin.com/in/sumit-sampang-rai/"
website: [
  {
    "text": "sumit-sampang-rai.github.io",
    "url": "https://sumit-sampang-rai.github.io/"
  }
]
about: "Sumit is a Senior Data Engineer with 11 years of IT experience. He specializes solving for US Healthcare Insurance and Workforce solution challenges using his diverse skill set and expertise. He excels in building enterprise data warehouses, augmenting it's data quality, automating workflows, writing software & scripts, and overcoming architectural & scalability obstacles. His role as a Data, DevOps, and Software Engineer enables him to face technical hurdles and achieve business objectives with top-notch results."
experiences:
  - entity: "Techkraft Inc."
    registrar: "Techkraft Inc. Pvt. Ltd."
    location: "Lalitpur, Nepal"
    experiences:
      - title_name: "Senior Data Engineer"
        start: "2023-01-02"
        responsibilities:
          - "Architected and developed the data quality solution for the data reconciliation and data quality rules. Architected data quality solution for the data spike and data drift. These products built the confidence on the data in every ingestion by automatically monitoring."
          - "Managed a team of six highly skilled Software Engineers, providing leadership and guidance in understanding business objectives, system architectures, workflows, and technical challenges, while collaborating daily with Nepal, India, and US team members to ensure seamless coordination across different time zones and cultural contexts."
          - "Streamlined and consolidated insurance claims data from multiple US Healthcare Insurance organizations, enhancing data usability and enabling efficient report generation."
          - "Architected and developed automated data pipelines on the Databricks Platform using PySpark or SparkSQL for seamless data extraction, loading, and transformation."
          - "Ensured timely delivery of project requirements and conducted thorough reviews to maintain high-quality standards."
          - "Facilitated cross-department communication and collaboration with Business Analyst (BA) and Quality Assurance (QA) teams, ensuring alignment and effective coordination throughout the project lifecycle."
          - "Mentored participants from Nepal and India in a US Healthcare Bootcamp for two months, providing guidance and expertise in healthcare data management and analytics."
        skills:
          - Data Quality
          - Databricks
          - Databricks Pipeline
          - SnowFlake
          - PySpark
          - Spark SQL
          - Python
          - Data Engineering
          - Data Warehousing
          - Docker
          - Containerization
          - ANTLR4
          - ETL / ELT
          - dbt
          - Terraform
          - Amazon Web Services
          - AWS S3
          - OLAP / OLTP
          - GitLab
          - Pandas
          - Excel
          - JSON / YAML
          - Parquet
          - REST APIs
          - JIRA
          - Scrum
  - entity: "Islington"
    registrar: "Islington College"
    location: "Kathmandu, Nepal"
    experiences:
      - title_name: "External Supervisor"
        hidden: true
        start: "2020-12-01"
        end: "2022-09-30"
        responsibilities:
          - "Guided and supported undergraduate students in completing their Final Year Projects (FYP) within deadlines."
          - "Mentored students throughout their projects, offering assistance and fostering a positive learning environment."
          - "Aligned students' projects with desired outcomes, monitored progress, and ensured focus on aims and objectives."
          - "Evaluated project works, assessed presentations, and provided detailed feedback during viva voce examinations."
        skills:
          - Mentoring
          - Guiding
          - Monitoring
          - Assessing
          - Evaluating
  - entity: "CloudFactory"
    registrar: "Sprout Technology Services Pvt. Ltd."
    location: "Kathmandu, Nepal"
    experiences:
      - title_name: "Senior Data Engineer"
        start: "2020-12-01"
        end: "2022-09-30"
        responsibilities:
          - "Collaborated with teams in Nepal, Kenya, and the UK to achieve data team goals and make ourselves successful."
          - "Successfully migrated data pipelines from Xplenty to Prefect orchestration, improving cost-effectiveness."
          - "Developed Python and Pandas pipelines for fetching and ingesting data from clients' REST APIs."
          - "Provided crucial support to the data team, overseeing technical operations of the enterprise data warehouse. Facilitated cross-departmental understanding of business operations, processes, and data origins."
          - "Implemented documentation and testing protocols, resulting in an 80% improvement in team performance."
          - "Supported the establishment of a self-service BI platform with accurate data delivery and user-friendly documentation."
          - "Developed dbt transformations following the Kimball approach for complete, accurate, and timely data processing."
          - "Created a CI pipeline in GitHub Actions, ensuring code quality checks, model validation, and data testing."
          - "Maintained data team standards and data accuracy."
          - "Orchestrated data pipelines using Prefect, transitioning from EC2 to enhance visibility and optimize resource allocation in the AWS Fargate environment."
        skills:
          - SnowFlake
          - dbt
          - Fivetran
          - Python
          - Data Engineering
          - Data Warehousing
          - Enterprise Data Warehouse
          - Kimball
          - Docker
          - Containerization
          - ETL / ELT
          - Prefect
          - Terraform
          - Amazon Web Services
          - AWS S3
          - AWS ECS
          - AWS ECR
          - AWS EC2
          - OLAP / OLTP
          - GitHub
          - GitHub Actions
          - Xplenty
          - Stitch
          - Pipelinewise
          - Singer
          - Pandas
          - Excel
          - REST APIs
          - JIRA
          - Scrum
          - Kanban
      - title_name: "Software Engineer, DevOps"
        start: "2018-10-01"
        end: "2020-11-30"
        responsibilities:
          - "Improved availability and stability of a critical communication microservice application, recognized and rewarded for achieving performance increase from 95% to 99%."
          - "Implemented a game-changing optimization, reducing EC2 Auto Scaling instance startup time by 70%."
          - "Replaced Ansible scripts with HashiCorp Packer for faster instance provisioning using custom AWS AMIs built with AWS CodeBuild."
          - "Developed optimized SQL queries for processing big data, collaborating with data scientists on PySpark and AWS Glue jobs."
          - "Orchestrated AWS Glue jobs and catalogs using AWS Step Functions and stored raw data in PostgreSQL for further processing and categorization."
          - "Troubleshot and resolved issues across multiple applications in development, test, and production environments."
          - "Monitored application performance proactively, optimizing operation and making necessary enhancements."
          - "Led the upgrade of legacy infrastructure to align with evolving business operations and leverage advanced AWS services."
          - "Migrated 200-300 instances to AWS VPC environment, enhancing security and internal connectivity."
          - "Collaborated with software engineering teams to achieve Scrum sprint goals, fostering effective teamwork and alignment."
        skills:
          - Ansible
          - Amazon Web Services
          - AWS Athena
          - AWS CloudFormation
          - AWS S3
          - AWS IAM
          - AWS ECS
          - AWS ECR
          - AWS EC2
          - AWS ELB
          - AWS RDS
          - AWS Glue
          - AWS Step Functions
          - GitHub
          - GitHub Actions
          - REST APIs
          - SSH
          - Jenkins
          - PostgreSQL
          - SQL
          - MongoDB
          - RabbitMQ
          - Docker
          - Containerization
          - Hashicorp Terraform
          - Hashicorp Packer
          - NGINX
          - Apache2
          - Burp Suite
          - JIRA
          - Scrum
  - entity: "Leapfrog Technology"
    registrar: "Leapfrog Technology Nepal Pvt. Ltd."
    location: "Kathmandu, Nepal"
    experiences:
      - title_name: "Software Engineer, DevOps"
        start: "2016-09-01"
        end: "2018-09-30"
        responsibilities:
          - "Developed Python and Ansible scripts to efficiently configure EC2 infrastructures, streamlining the deployment process and ensuring consistent configuration management."
          - "Implemented Jenkins pipelines to automate the deployment of source codes, enabling seamless and efficient deployment workflows."
          - "Designed and structured AWS resources utilizing Auto Scaling and Elastic Load Balancing through CloudFormation."
          - "Configured and resolved issues related to these resources to optimize performance and scalability."
          - "Deployed and configured pfSense firewall for the intranet, including traffic shaping for optimal working environments."
          - "Configured additional security measures such as VPN (OpenVPN), Snort IPS, and Squid web filter to enhance network security."
          - "Engineered, implemented, and monitored comprehensive security measures to safeguard computer systems, networks, and sensitive information, ensuring the integrity and confidentiality of data."
          - "Established FreeIPA and Active Directory identity managers to centralize employee identities and manage access permissions across networks and servers, enhancing security and simplifying user management processes."
        skills:
          - Amazon Web Services
          - AWS CloudFormation
          - AWS S3
          - AWS IAM
          - AWS EC2
          - AWS ELB
          - AWS RDS
          - AWS Route53
          - Ansible
          - GitHub
          - REST APIs
          - SSH
          - Jenkins
          - SQL
          - Docker
          - Containerization
          - Hashicorp Terraform
          - NGINX
          - Apache2
          - Burp Suite
          - SSL Management
          - pfSense
          - OpenVPN
          - FreeIPA
          - Sophos
          - Scrum
  - entity: "Incessant Rain Animation Studios"
    registrar: "Incessant Rain Animation Studios Pvt. Ltd."
    location: "Kathmandu, Nepal"
    experiences:
      - title_name: "Software Developer"
        start: "2014-12-01"
        end: "2016-09-23"
        responsibilities:
          - "Designed and maintained file pipelines for seamless file transfers across departments, supporting animators in accessing and uploading necessary files."
          - "Collaborated with the .NET programming team to automate render job handling, resulting in a streamlined rendering process with improved efficiency and reduced manual intervention."
          - "Developed a customized remote services manager tool for the rendering department, simplifying render job management and increasing productivity while minimizing administrative overhead."
        skills:
          - Python
          - REST APIs
          - Microsoft SQL Server
          - SQL
          - Regex
educations:
  - entity: "Alliance Fran√ßaise, Katmandou"
    location: "Lalitpur, Nepal"
    educations:
      - course_name: "French language"
        start: "2023-08-01"
  - entity: "London Metropolitan University"
    location: "London, UK"
    educations:
      - course_name: "Masters of Science in IT & Applied Security"
        start: "2019-09-22"
        end: "2022-06-09"
      - course_name: "Bachelors of Science (Hons) in Computer Networking and IT Security"
        start: "2012-02-01"
        end: "2014-11-06"
  - entity: "Informatics Academy"
    location: "Victoria Street, Singapore"
    educations:
      - course_name: "International Diploma in Information and Communication Technology"
        start: "2011-04-01"
        end: "2011-12-31"
skills:
  - Data Quality
  - Python
  - DBT
  - SQL
  - SnowFlake
  - Databricks
  - ETL / ELT
  - PySpark
  - AWS
  - Docker Containerization
  - CI/CD
